\section{Compilere}
Compilere er grundstenen i alt programmering, og store dele af datalogien, som vi kender den i dag. De tidlige udgaver af programmer og styresystemer blev skrevet i ren maskinkode - en disciplin som de færreste mennesker er i stand til at udføre. Derfor blev konceptet med høj-niveau sprog opfundet. Det vil sige at man kan skrive et stykke software, med bogstaver og ord som er væsentligt mere læsbar for mennesket. Herefter transformerer et andet stykke software denne tekst om til maskinkode - dette kaldes en compiler.

\tikzfigure{Figurer/TikZ/CompilerOpbygning.tex}{Opbygningen af en compiler}{Compiler-opbygning}

\noindent Som nævnt har en compiler den funktion at omdanne et højniveau-sprog til maskinkode. Kigger man på figur \ref{fig:Compiler-opbygning} ses det dog at der flere andre ting undervejs.

\subsection{Syntax Analysis}\label{ssec:syntaxanalysis}
Den første del af en compiler, syntaksanalysen, har til ansvar at læse kildekoden som ren tekst og omdanne det til et abstrakt syntakstræ, som efterfølgende kan bruges i det videre arbejde mod maskinkoden. Denne analyse er typisk opdelt i to underdele: Scanneren og parseren. 

\subsubsection{Scanner}
Scanneren som er den første del af compileren der bliver kørt har til opgave at læse kildekoden og dele den op i tokens, som er de mindste dele af et sprog. Keywords i et sprog er et eksempel på tokens som skal læses. Til at illustrere dette ses her et kodestykke fra sproget Port der bygger på PLC++.

% Q#0.0 = I#0.1  == I#0.2 && I#0.3 != true;
\sfix{Indsæt kode}

Alle tokens er defineret på følgende måde:
\sfix{Skal indsættes}
%semi = ';';
%equal_operator = '==';
%not_equal_operator = '!=';
%and_operator = '\&\&';
%or_operator = '||';
%assignment_operator = '=';

%true_keyword = 'true';
%false_keyword = 'false';

%decimal_literal = (digit)+ '.' (digit)+;
%port_identifier = ('I' | 'Q' | 'M') '\#';

%white_space = (sp | ht | ff | line_terminator)+;

white\_space skal dog ignoreres af scanneren.

En scanner indlæser de forskellige "ord"\mbox{}, og laver dem om til tokens som parseren senere kan bruge. Et eksempel på en scanner til følgende tokens implementeret i Java kan ses i bilag \sfix{Bilag med scanner}.

% Q#0.0 = true;

\begin{table}[H]
\centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{port_identifier} & \textbf{decimal_literal} & \textbf{assignment_operator} & \textbf{true_keyword} & \textbf{semi} \\ \hline
    Q\#          & 0.0          & =                   & true              & ;             \\ \hline
    \end{tabular}
\caption{\textit{Opdeling af tokens}}
\label{tab:tokensMT}
\end{table}

%For at illustrere dette, ses et lille kodestykke i sproget Mini Triangle i kodeeksempel \ref{code:minitriangleforscanner}.

%\MT{Kode/MiniTriangleForScanner.mt}{Lille program i Mini Triangle}{minitriangleforscanner}

%\noindent Hvis der tager udgangspunkt i linje 1 fra kode \ref{code:minitriangleforscanner} ses det at der er nogle forskellige "ord"\mbox{}. Det er disse ord der skal forstås som tokens. Disse er inddelt i forskellige kategorier - typisk én kategori til hvert keyword\fn{Keyword}{Et bestemt ord i et programmeringssprog, som er reserveret til et bestemt formål.}, for eksempel \textit{let} og \textit{var}, samt identifiers. Opdelingen i tokens ses i tabel \ref{tab:tokensMT}

\begin{table}[H]
\centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{let} & \textbf{var} & \textbf{identifier} & \textbf{colon} & \textbf{identifier} \\ \hline
    let          & var          & y                   & :              & Integer             \\ \hline
    \end{tabular}
\caption{\textit{Opdeling af tokens}}
\label{tab:tokensMT}
\end{table}

\noindent Da input'et nu er scannet og opdelt i tokens, er det muligt at bygge et abstrakt syntakstræ.

\subsubsection{Parser}
Som nævnt er opgaven nu at få bygget et abstrakt syntakstræ. Fordelene ved at arbejde med træer generelt, er muligheden for at gennemløbe det på flere forskellige måder - eksempelvis ved hjælp af Visitor-mønstret, som forklares nærmere i afsnit \ref{sec:visitor}

\figur{Figurer/MTAST.png}{Abstrakt syntakstræ baseret på kodeeksempel \ref{code:minitriangleforscanner}}{MTAST}{1.0}

\noindent På figur \ref{fig:MTAST} ses et sådant træ for koden vist i eksempel \ref{code:minitriangleforscanner}. For at forstå hvordan træet er bygget op, er det dog nødvendigt også at kende til \gls{cfg}. Denne forklares i dybden i afsnit x.x\mfix{Mangler ref}, men den konkrete \gls{cfg} for Mini Triangle kan ses i bilag \ref{bil:minitriangle}. Eksempelvis ses det øverste i den øverste del af træet at \textit{single-Command} består af "\textit{let} Declaration \textit{in} single-Command"\mbox{}, hvilket passer med grammatikken.

%%%% IMPLEMENTATION

\subsubsection{Implementation}
\wip{}

I afsnit \ref{ssec:toolsforcc} omtales flere forskellige værktøjer til generering af compilere (også kaldet CompilerCompilers). Det er blevet valgt at gøre brug af SableCC, da denne indeholder en del funktioner som er nyttige for udarbejdelsen af PLC++. Blandt disse kan nævnes at det er en \gls{lalr}1-parser og derudover genereres SableCC et \gls{ast} med indbyggede metoder til at gennemløbe træet ved hjælp af Visitor Mønsteret (yderligere forklaret i afsnit \ref{sec:visitor}). 

SableCC sørger altså for at generere både en scanner samt parser. For at kunne gøre dette, er SableCC afhængig af en konfigurationsfil som indeholder den kontekst-fri grammatik samt forskellige indstillinger af SableCC. Et udsnit af grammatikken anvendt til at generere parser/scanner til PLC++, ses på kode \ref{code:cfgudsnit}

\SCC{Kode/Udsnit.scc}{Udsnit af CFG i SableCC-syntax}{cfgudsnit}

\noindent Det er værd at bemærke at rækkefølgen ikke er bevaret i kodeeksemplet, men er opsat efter forklaringen.

På linje 1-2 ses definitionen for et \textit{while\_statement} - altså en løkke af typen while. Teksten i tuborgklammerne angiver navnet, som kan bruges til intern brug i programmet. Herefter fortæller grammatikken hvad et \textit{while\_statement} består af. Det første, \textit{while\_keyword}, er defineret på linje 4 som værende teksten "while"\mbox{}. Da det ikke er muligt at skrive keywords på samme måde som i \gls{bnf}, er det nødvendigt at definere alle i starten af konfigurationsfilen.

Et eksempel på dette kommer også til udtryk ved \textit{l\_par} og \textit{r\_par} som henholdsvis dækker og venstre og højre parentes - disse er defineret på linje 6-7 i kodeeksemplet. Imellem de to parenteser findes \textit{expr}, en expression. Definitionen på denne ses i linje 9-12, som fortæller at det kan være to expressions sammenlignet ved hjælp af \textit{and\_operator} eller \textit{or\_operator}. Produktionen til \textit{expr2} er udeladt i dette kodeeksempel, men kan findes i den fulde udgave af SableCC-konfigurationen i bilag \ref{bil:sablecc}.

Det sidste element er \textit{scope}, som på linje 14-15 er defineret ved hjælp af nul eller en \textit{statements} omgivet af tuborgklammer.\\

\noindent Når compileren skal læse kildekoden, for at få dette opsat til tokens, er der, som nævnt i afsnit x.x\mfix{ref} flere måder at implementere det på. I compileren til PLC++ er det blevet implementeret ved hjælp af state machines. Konkret genereres først en \gls{nfa}, som efterfølgende omdannes til en \gls{dfa}.

\tikzfigure{Figurer/TikZ/SableCC_NFA.tex}{En NFA genereret af SableCC}{sableccnfa}

\noindent \textbf{Formel definition af NFA i figur \ref{fig:sableccnfa}}\\
\noindent $Q$ = \{$s$, $q_1$, $q_2$, $q_3$, $q_4$, $q_5$, $q_6$, $q_7$, $q_8$, $q_9$, $q_{10}$, $q_{11}$, $q_{12}$, $q_{13}$, $f$\}\\
\noindent $\Sigma$ = \{$\epsilon$, $I$, $Q$, $M$, $A$, $\#$\}\\
\noindent $\delta$ = Se tabel \ref{tab:nfadelta}\\
\noindent $q_0$ = $s$\\
\noindent $F$= \{$f$\}\\

\begin{table}[H]
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|}
\hline
           & $s$              & $q_{1}$ & $q_{2}$ & $q_{3}$ & $q_{4}$ & $q_{5}$ & $q_{6}$ & $q_{7}$ & $q_{8}$ & $q_{9}$ & $q_{10}$ & $q_{11}$ & $q_{12}$ & $q_{13}$ & $f$ \\ \hline
$\epsilon$ & \{$q_{1}$ ,$q_{3}$ ,$q_{5}$ ,$q_{7}$ ,$q_{10}$\} &   & $q_{13}$ &   & $q_{13}$ &   & $q_{13}$ &   &   & $q_{13}$ &    &    & $q_{13}$ &    &   \\ \hline
$I$          &                & $q_{2}$ &    &   &    &   &    &   & $q_{9}$ &    &    &    &    &    &   \\ \hline
$Q$          &                &   &    & $q_{4}$ &    &   &    &   &   &    &    & $q_{12}$ &    &    &   \\ \hline
$M$          &                &   &    &   &    & $q_{6}$ &    &   &   &    &    &    &    &    &   \\ \hline
$A$          &                &   &    &   &    &   &    & $q_{8}$ &   &    & $q_{11}$ &    &    &    &   \\ \hline
\#         &                &   &    &   &    &   &    &   &   &    &    &    &    & $f$  &   \\ \hline
\end{tabular}
	\caption{\textit{Transitionsfunktion til NFA (alle tommer celler angiver den tomme mængde)}}
    \label{tab:nfadelta}
\end{table}

\noindent På figur \ref{fig:sableccnfa} ses hvordan en \textit{port\_identifier} (defineret på linje 20 i kode \ref{code:cfgudsnit}) genkendes. Hvis der i programmet angives AQ\#7 arbejdes der med analoge output-port 7. I \gls{nfa}'en starter man i state \textit{s}, hvorefter der foretages et ikke-deterministisk valg om at gå videre til state  \textit{q\textunderscript{10}}. Derefter læses bogstavet A, som får maskinen til at gå til \textit{q\textunderscript{11}}. Efter et Q bliver state \textit{q\textunderscript{12}} sprunget over, da $\epsilon$ (den tomme streng) lader den gå videre til state \textit{q\textunderscript{13}}. Efter at have læst \# kommer den i det sidste state, \textit{f}, som er en accept state - og ordet er derved accepteret. \\

\noindent Som tidligere nævnt, er dette ikke den konkrete grammatik, men opsætningen af denne i SableCC. Den korrekte grammatik, skrevet i \gls{ebnf} ses på grammatik \ref{gra:udsnit}. Den fulde kontekstfri grammatik findes i bilag \ref{bil:cfg}

\input{Kode/CFG/Udsnit.tex}

\noindent Ud fra grammatikken kan SableCC generere et \gls{ast}. Der vil her blive givet et eksempel ved hjælp af dette udtrykket, som ses i kode \ref{code:exprforast}

\AnsiC{Kode/ExprForAST.c}{Udtryk der bruges til at bygge AST}{exprforast}

\noindent Der bruges left-most derivation til at bygge træet. Dette vil sige at reglerne (også kaldet produktioner) udvides fra venstre mod højre. Ved at bygge træet, kan det også give mulighed for at opdage tvetydig grammatik - dette ses ved at det er muligt at lave to forskellige \gls{ast}'er ud fra samme regler og sætning.

\tikzfigure{Figurer/TikZ/AST.tex}{AST fra PLC++}{astexample}

\noindent Træet er nu bygget, og alt er klar til at gå videre til næste trin - at dekorere træet med typer i den kontekstuelle analyse.

\subsection{Code Generation}
